#  Week 2: Feature Extraction and Word Representations

## ðŸ“Œ Briefly
> Bag of Words, TF-IDF \
> One-hot vectors, Count-Based Methods \
> Word2Vec, Glove, FastText \
> Evaluation and Current State \

---

## ðŸ“š Additional Materials


- ðŸ“„ [NLP course for you, Word Embeddings chapter](https://lena-voita.github.io/nlp_course/word_embeddings.html) â€” overview
- ðŸ“„ [Bag of Words](https://www.geeksforgeeks.org/nlp/bag-of-words-bow-model-in-nlp/) â€” basic feature extraction
- ðŸ“„ [Word Representations](https://slds-lmu.github.io/seminar_nlp_ss20/foundationsapplications-of-modern-nlp.html) - chapter about representations
- ðŸ“„ [Hierarchical Softmax](https://medium.com/@abhishekjainindore24/hierarchial-softmax-for-word-embeddings-47e1ca398ed6) - paper about impovement technique in Word2Vec
---